{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet Model ZOO.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVpPrkGhQLeI"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import importlib\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "import logging\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torch.backends.cudnn\n",
        "import torchvision.utils\n",
        "import torch.nn.functional as F\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prnXxVyJTZir"
      },
      "source": [
        "class block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride = 1, convert = None):\n",
        "    super(block, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.convert = convert\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = x.clone()\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.conv3(out)\n",
        "    out = self.bn3(out)\n",
        "\n",
        "    if self.convert:\n",
        "      y = self.convert(y)\n",
        "\n",
        "    out = out + y\n",
        "    return out"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWd7v7D_TeCE"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, layers, classes = 10):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.conv = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn = nn.BatchNorm2d(16)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.in_channel = 16\n",
        "\n",
        "    self.layer1 = self.make_layer(block, 16, layers[0])\n",
        "    self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
        "    self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
        "    \n",
        "    self.avg_pool = nn.AvgPool2d(8)\n",
        "    self.fc = nn.Linear(64, classes)\n",
        "\n",
        "  def make_layer(self, block, out_channel, num_layers, stride = 1):\n",
        "    layer = []\n",
        "    conv = None\n",
        "    if stride != 1 or self.in_channel != out_channel:\n",
        "      conv = nn.Sequential(\n",
        "          nn.Conv2d(self.in_channel, \n",
        "                    out_channel, \n",
        "                    kernel_size=3,\n",
        "                    stride=stride, \n",
        "                    padding=1, \n",
        "                    bias=False), \n",
        "          nn.BatchNorm2d(out_channel))\n",
        "    \n",
        "    layer.append(block(self.in_channel, out_channel, stride, conv))\n",
        "    self.in_channel = out_channel\n",
        "\n",
        "    for _ in range(num_layers - 1):\n",
        "      layer.append(block(self.in_channel, out_channel))\n",
        "\n",
        "    return nn.Sequential(*layer)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.conv(x)\n",
        "    out = self.bn(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.avg_pool(out)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc(out)\n",
        "    return out"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNXOgLaY_nW9",
        "outputId": "9290d25f-8272-420c-f033-b216d303e525"
      },
      "source": [
        "transform = transforms.Compose([transforms.Pad(4),transforms.RandomHorizontalFlip(),transforms.RandomCrop(32),transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "test_transform  = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='../../data/', train=True,transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='../../data/', train=False,transform=test_transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=100, shuffle=False)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kj_7G0phsdN"
      },
      "source": [
        "depth = 3\n",
        "option = 'A'\n",
        "block_type = 'basic'\n",
        "epochs = 50\n",
        "batch_size = 128\n",
        "base_lr = 0.01\n",
        "lr_decay = 0.1\n",
        "weight_decay = 1e-4\n",
        "momentum = 0.9\n",
        "milestones = '[80, 120]'\n",
        "device = \"cuda\"\n",
        "num_workers = 3\n",
        "\n",
        "model = ResNet(block,[10,10,10]).to(device)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F6jK4y0htGa"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=base_lr)\n",
        "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=lr_decay)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=lr_decay)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OvYBVoMmeuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c8e4c5a-5564-40d8-f305-9d0e41c35dce"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (i+1) % 100 == 0:\n",
        "      print (\"Epoch {}, Step {} Loss: {:.4f}\".format(epoch+1, i+1, loss.item()))   \n",
        "  scheduler.step()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Step 100 Loss: 1.9840\n",
            "Epoch 1, Step 200 Loss: 1.5997\n",
            "Epoch 1, Step 300 Loss: 1.5193\n",
            "Epoch 1, Step 400 Loss: 1.6561\n",
            "Epoch 1, Step 500 Loss: 1.5049\n",
            "Epoch 2, Step 100 Loss: 1.3368\n",
            "Epoch 2, Step 200 Loss: 1.2044\n",
            "Epoch 2, Step 300 Loss: 1.2405\n",
            "Epoch 2, Step 400 Loss: 1.1911\n",
            "Epoch 2, Step 500 Loss: 0.9929\n",
            "Epoch 3, Step 100 Loss: 1.1123\n",
            "Epoch 3, Step 200 Loss: 1.0030\n",
            "Epoch 3, Step 300 Loss: 0.9903\n",
            "Epoch 3, Step 400 Loss: 0.9908\n",
            "Epoch 3, Step 500 Loss: 0.9906\n",
            "Epoch 4, Step 100 Loss: 1.2199\n",
            "Epoch 4, Step 200 Loss: 0.9797\n",
            "Epoch 4, Step 300 Loss: 0.9328\n",
            "Epoch 4, Step 400 Loss: 0.7106\n",
            "Epoch 4, Step 500 Loss: 0.9801\n",
            "Epoch 5, Step 100 Loss: 0.6875\n",
            "Epoch 5, Step 200 Loss: 0.8400\n",
            "Epoch 5, Step 300 Loss: 0.7367\n",
            "Epoch 5, Step 400 Loss: 0.6607\n",
            "Epoch 5, Step 500 Loss: 0.5957\n",
            "Epoch 6, Step 100 Loss: 0.6292\n",
            "Epoch 6, Step 200 Loss: 0.6026\n",
            "Epoch 6, Step 300 Loss: 0.6616\n",
            "Epoch 6, Step 400 Loss: 0.6281\n",
            "Epoch 6, Step 500 Loss: 0.5802\n",
            "Epoch 7, Step 100 Loss: 0.4433\n",
            "Epoch 7, Step 200 Loss: 0.3666\n",
            "Epoch 7, Step 300 Loss: 0.4296\n",
            "Epoch 7, Step 400 Loss: 0.4351\n",
            "Epoch 7, Step 500 Loss: 0.7072\n",
            "Epoch 8, Step 100 Loss: 0.3971\n",
            "Epoch 8, Step 200 Loss: 0.5283\n",
            "Epoch 8, Step 300 Loss: 0.5255\n",
            "Epoch 8, Step 400 Loss: 0.3988\n",
            "Epoch 8, Step 500 Loss: 0.4177\n",
            "Epoch 9, Step 100 Loss: 0.4264\n",
            "Epoch 9, Step 200 Loss: 0.4502\n",
            "Epoch 9, Step 300 Loss: 0.4506\n",
            "Epoch 9, Step 400 Loss: 0.5209\n",
            "Epoch 9, Step 500 Loss: 0.2713\n",
            "Epoch 10, Step 100 Loss: 0.5731\n",
            "Epoch 10, Step 200 Loss: 0.6219\n",
            "Epoch 10, Step 300 Loss: 0.3936\n",
            "Epoch 10, Step 400 Loss: 0.5993\n",
            "Epoch 10, Step 500 Loss: 0.4599\n",
            "Epoch 11, Step 100 Loss: 0.3906\n",
            "Epoch 11, Step 200 Loss: 0.4952\n",
            "Epoch 11, Step 300 Loss: 0.5185\n",
            "Epoch 11, Step 400 Loss: 0.2674\n",
            "Epoch 11, Step 500 Loss: 0.2667\n",
            "Epoch 12, Step 100 Loss: 0.4359\n",
            "Epoch 12, Step 200 Loss: 0.4369\n",
            "Epoch 12, Step 300 Loss: 0.3488\n",
            "Epoch 12, Step 400 Loss: 0.3958\n",
            "Epoch 12, Step 500 Loss: 0.3270\n",
            "Epoch 13, Step 100 Loss: 0.4553\n",
            "Epoch 13, Step 200 Loss: 0.5030\n",
            "Epoch 13, Step 300 Loss: 0.3431\n",
            "Epoch 13, Step 400 Loss: 0.3846\n",
            "Epoch 13, Step 500 Loss: 0.2936\n",
            "Epoch 14, Step 100 Loss: 0.3486\n",
            "Epoch 14, Step 200 Loss: 0.3775\n",
            "Epoch 14, Step 300 Loss: 0.4512\n",
            "Epoch 14, Step 400 Loss: 0.3752\n",
            "Epoch 14, Step 500 Loss: 0.3903\n",
            "Epoch 15, Step 100 Loss: 0.2869\n",
            "Epoch 15, Step 200 Loss: 0.3597\n",
            "Epoch 15, Step 300 Loss: 0.3673\n",
            "Epoch 15, Step 400 Loss: 0.4079\n",
            "Epoch 15, Step 500 Loss: 0.4086\n",
            "Epoch 16, Step 100 Loss: 0.3663\n",
            "Epoch 16, Step 200 Loss: 0.3505\n",
            "Epoch 16, Step 300 Loss: 0.4197\n",
            "Epoch 16, Step 400 Loss: 0.4814\n",
            "Epoch 16, Step 500 Loss: 0.3944\n",
            "Epoch 17, Step 100 Loss: 0.4724\n",
            "Epoch 17, Step 200 Loss: 0.3622\n",
            "Epoch 17, Step 300 Loss: 0.3849\n",
            "Epoch 17, Step 400 Loss: 0.4777\n",
            "Epoch 17, Step 500 Loss: 0.3914\n",
            "Epoch 18, Step 100 Loss: 0.4058\n",
            "Epoch 18, Step 200 Loss: 0.4135\n",
            "Epoch 18, Step 300 Loss: 0.4275\n",
            "Epoch 18, Step 400 Loss: 0.3717\n",
            "Epoch 18, Step 500 Loss: 0.4092\n",
            "Epoch 19, Step 100 Loss: 0.2705\n",
            "Epoch 19, Step 200 Loss: 0.4541\n",
            "Epoch 19, Step 300 Loss: 0.2276\n",
            "Epoch 19, Step 400 Loss: 0.3558\n",
            "Epoch 19, Step 500 Loss: 0.4218\n",
            "Epoch 20, Step 100 Loss: 0.3880\n",
            "Epoch 20, Step 200 Loss: 0.3775\n",
            "Epoch 20, Step 300 Loss: 0.4813\n",
            "Epoch 20, Step 400 Loss: 0.4507\n",
            "Epoch 20, Step 500 Loss: 0.4254\n",
            "Epoch 21, Step 100 Loss: 0.5942\n",
            "Epoch 21, Step 200 Loss: 0.3195\n",
            "Epoch 21, Step 300 Loss: 0.3914\n",
            "Epoch 21, Step 400 Loss: 0.5263\n",
            "Epoch 21, Step 500 Loss: 0.3250\n",
            "Epoch 22, Step 100 Loss: 0.4203\n",
            "Epoch 22, Step 200 Loss: 0.3908\n",
            "Epoch 22, Step 300 Loss: 0.3877\n",
            "Epoch 22, Step 400 Loss: 0.5292\n",
            "Epoch 22, Step 500 Loss: 0.6020\n",
            "Epoch 23, Step 100 Loss: 0.3924\n",
            "Epoch 23, Step 200 Loss: 0.4388\n",
            "Epoch 23, Step 300 Loss: 0.2833\n",
            "Epoch 23, Step 400 Loss: 0.2840\n",
            "Epoch 23, Step 500 Loss: 0.3843\n",
            "Epoch 24, Step 100 Loss: 0.3517\n",
            "Epoch 24, Step 200 Loss: 0.3659\n",
            "Epoch 24, Step 300 Loss: 0.4299\n",
            "Epoch 24, Step 400 Loss: 0.3395\n",
            "Epoch 24, Step 500 Loss: 0.5573\n",
            "Epoch 25, Step 100 Loss: 0.5611\n",
            "Epoch 25, Step 200 Loss: 0.4281\n",
            "Epoch 25, Step 300 Loss: 0.3419\n",
            "Epoch 25, Step 400 Loss: 0.3764\n",
            "Epoch 25, Step 500 Loss: 0.3897\n",
            "Epoch 26, Step 100 Loss: 0.4255\n",
            "Epoch 26, Step 200 Loss: 0.3187\n",
            "Epoch 26, Step 300 Loss: 0.4281\n",
            "Epoch 26, Step 400 Loss: 0.3600\n",
            "Epoch 26, Step 500 Loss: 0.3322\n",
            "Epoch 27, Step 100 Loss: 0.3991\n",
            "Epoch 27, Step 200 Loss: 0.3616\n",
            "Epoch 27, Step 300 Loss: 0.3525\n",
            "Epoch 27, Step 400 Loss: 0.3247\n",
            "Epoch 27, Step 500 Loss: 0.4233\n",
            "Epoch 28, Step 100 Loss: 0.4041\n",
            "Epoch 28, Step 200 Loss: 0.3480\n",
            "Epoch 28, Step 300 Loss: 0.2720\n",
            "Epoch 28, Step 400 Loss: 0.2168\n",
            "Epoch 28, Step 500 Loss: 0.5823\n",
            "Epoch 29, Step 100 Loss: 0.5524\n",
            "Epoch 29, Step 200 Loss: 0.4635\n",
            "Epoch 29, Step 300 Loss: 0.3224\n",
            "Epoch 29, Step 400 Loss: 0.4476\n",
            "Epoch 29, Step 500 Loss: 0.3782\n",
            "Epoch 30, Step 100 Loss: 0.4178\n",
            "Epoch 30, Step 200 Loss: 0.3366\n",
            "Epoch 30, Step 300 Loss: 0.3008\n",
            "Epoch 30, Step 400 Loss: 0.4223\n",
            "Epoch 30, Step 500 Loss: 0.4947\n",
            "Epoch 31, Step 100 Loss: 0.3565\n",
            "Epoch 31, Step 200 Loss: 0.3424\n",
            "Epoch 31, Step 300 Loss: 0.3119\n",
            "Epoch 31, Step 400 Loss: 0.4584\n",
            "Epoch 31, Step 500 Loss: 0.3681\n",
            "Epoch 32, Step 100 Loss: 0.3554\n",
            "Epoch 32, Step 200 Loss: 0.5958\n",
            "Epoch 32, Step 300 Loss: 0.4574\n",
            "Epoch 32, Step 400 Loss: 0.3526\n",
            "Epoch 32, Step 500 Loss: 0.4169\n",
            "Epoch 33, Step 100 Loss: 0.3889\n",
            "Epoch 33, Step 200 Loss: 0.3275\n",
            "Epoch 33, Step 300 Loss: 0.3851\n",
            "Epoch 33, Step 400 Loss: 0.4268\n",
            "Epoch 33, Step 500 Loss: 0.3371\n",
            "Epoch 34, Step 100 Loss: 0.2938\n",
            "Epoch 34, Step 200 Loss: 0.4099\n",
            "Epoch 34, Step 300 Loss: 0.4510\n",
            "Epoch 34, Step 400 Loss: 0.3178\n",
            "Epoch 34, Step 500 Loss: 0.3106\n",
            "Epoch 35, Step 100 Loss: 0.4334\n",
            "Epoch 35, Step 200 Loss: 0.3005\n",
            "Epoch 35, Step 300 Loss: 0.4317\n",
            "Epoch 35, Step 400 Loss: 0.3698\n",
            "Epoch 35, Step 500 Loss: 0.3650\n",
            "Epoch 36, Step 100 Loss: 0.3702\n",
            "Epoch 36, Step 200 Loss: 0.4049\n",
            "Epoch 36, Step 300 Loss: 0.2787\n",
            "Epoch 36, Step 400 Loss: 0.3912\n",
            "Epoch 36, Step 500 Loss: 0.3174\n",
            "Epoch 37, Step 100 Loss: 0.3538\n",
            "Epoch 37, Step 200 Loss: 0.5018\n",
            "Epoch 37, Step 300 Loss: 0.3455\n",
            "Epoch 37, Step 400 Loss: 0.4244\n",
            "Epoch 37, Step 500 Loss: 0.3859\n",
            "Epoch 38, Step 100 Loss: 0.3917\n",
            "Epoch 38, Step 200 Loss: 0.5086\n",
            "Epoch 38, Step 300 Loss: 0.4798\n",
            "Epoch 38, Step 400 Loss: 0.4242\n",
            "Epoch 38, Step 500 Loss: 0.3284\n",
            "Epoch 39, Step 100 Loss: 0.3578\n",
            "Epoch 39, Step 200 Loss: 0.3900\n",
            "Epoch 39, Step 300 Loss: 0.3262\n",
            "Epoch 39, Step 400 Loss: 0.4262\n",
            "Epoch 39, Step 500 Loss: 0.1878\n",
            "Epoch 40, Step 100 Loss: 0.2345\n",
            "Epoch 40, Step 200 Loss: 0.4483\n",
            "Epoch 40, Step 300 Loss: 0.3669\n",
            "Epoch 40, Step 400 Loss: 0.2990\n",
            "Epoch 40, Step 500 Loss: 0.3439\n",
            "Epoch 41, Step 100 Loss: 0.3373\n",
            "Epoch 41, Step 200 Loss: 0.3766\n",
            "Epoch 41, Step 300 Loss: 0.2953\n",
            "Epoch 41, Step 400 Loss: 0.4574\n",
            "Epoch 41, Step 500 Loss: 0.5187\n",
            "Epoch 42, Step 100 Loss: 0.3788\n",
            "Epoch 42, Step 200 Loss: 0.4182\n",
            "Epoch 42, Step 300 Loss: 0.3371\n",
            "Epoch 42, Step 400 Loss: 0.2451\n",
            "Epoch 42, Step 500 Loss: 0.4654\n",
            "Epoch 43, Step 100 Loss: 0.2356\n",
            "Epoch 43, Step 200 Loss: 0.4207\n",
            "Epoch 43, Step 300 Loss: 0.5114\n",
            "Epoch 43, Step 400 Loss: 0.3816\n",
            "Epoch 43, Step 500 Loss: 0.4148\n",
            "Epoch 44, Step 100 Loss: 0.6074\n",
            "Epoch 44, Step 200 Loss: 0.3395\n",
            "Epoch 44, Step 300 Loss: 0.4803\n",
            "Epoch 44, Step 400 Loss: 0.4250\n",
            "Epoch 44, Step 500 Loss: 0.2958\n",
            "Epoch 45, Step 100 Loss: 0.3221\n",
            "Epoch 45, Step 200 Loss: 0.5028\n",
            "Epoch 45, Step 300 Loss: 0.3576\n",
            "Epoch 45, Step 400 Loss: 0.5124\n",
            "Epoch 45, Step 500 Loss: 0.4979\n",
            "Epoch 46, Step 100 Loss: 0.4015\n",
            "Epoch 46, Step 200 Loss: 0.4437\n",
            "Epoch 46, Step 300 Loss: 0.4232\n",
            "Epoch 46, Step 400 Loss: 0.2667\n",
            "Epoch 46, Step 500 Loss: 0.3593\n",
            "Epoch 47, Step 100 Loss: 0.3025\n",
            "Epoch 47, Step 200 Loss: 0.3769\n",
            "Epoch 47, Step 300 Loss: 0.3572\n",
            "Epoch 47, Step 400 Loss: 0.4117\n",
            "Epoch 47, Step 500 Loss: 0.3519\n",
            "Epoch 48, Step 100 Loss: 0.2708\n",
            "Epoch 48, Step 200 Loss: 0.3954\n",
            "Epoch 48, Step 300 Loss: 0.4404\n",
            "Epoch 48, Step 400 Loss: 0.3361\n",
            "Epoch 48, Step 500 Loss: 0.2911\n",
            "Epoch 49, Step 100 Loss: 0.3282\n",
            "Epoch 49, Step 200 Loss: 0.3465\n",
            "Epoch 49, Step 300 Loss: 0.3629\n",
            "Epoch 49, Step 400 Loss: 0.3287\n",
            "Epoch 49, Step 500 Loss: 0.3633\n",
            "Epoch 50, Step 100 Loss: 0.4171\n",
            "Epoch 50, Step 200 Loss: 0.4253\n",
            "Epoch 50, Step 300 Loss: 0.3266\n",
            "Epoch 50, Step 400 Loss: 0.3421\n",
            "Epoch 50, Step 500 Loss: 0.4372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra-lAy_ShtM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dffdfe2a-1caa-4a56-c3f0-af00dfe35760"
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy ( test images ) : {} %'.format(100 * correct / total))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy ( test images ) : 78.4 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKdhP8kdtg4I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}